{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import keras\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Input,BatchNormalization,MaxPooling2D,Conv2DTranspose,concatenate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "size_pat=64 # pixel number of generated data in one dimension\n",
    "max_pixel_num=333 # each image is 333 x 333 pixels\n",
    "sample_1d = int(max_pixel_num/size_pat) # each image's sample number in one dimension\n",
    "sample_num_per_img = int(math.pow(sample_1d,2))\n",
    "print(\"Every image produces\",sample_num_per_img,\"non-repeating training images.\")\n",
    "class_to_train = 3 # select a class to train at one time from [1,9]\n",
    "\n",
    "least = 1\n",
    "largest = 26\n",
    "print(\"Using images from\",least,\"to\",largest,\".\")\n",
    "\n",
    "# Generate 4d matrix data from image number \"least\" to \"largest\"\n",
    "total_sample_num = sample_num_per_img*(largest - least + 1)\n",
    "patch=np.ones((total_sample_num,size_pat,size_pat,6),float)\n",
    "label=np.zeros((total_sample_num,size_pat,size_pat,1),int)\n",
    "class_count = np.zeros(9,dtype=int)\n",
    "\n",
    "for i in range(least,largest+1):\n",
    "    s = './data/Image'+str(i)+'_allData.csv'\n",
    "    mydata = np.genfromtxt(s, delimiter=',')\n",
    "    for rs in range(sample_1d):# sample image row index\n",
    "        for cs in range(sample_1d):# sample image column index\n",
    "            p_index = (i-least)*sample_num_per_img+cs*sample_1d+rs\n",
    "            for ri in range(size_pat):# image pixel row index\n",
    "                for ci in range(size_pat):# image pixel column index\n",
    "                    data_index = (ci+cs*size_pat)*max_pixel_num+(rs*size_pat+ri)\n",
    "                    patch[p_index,ri,ci,:] = mydata[data_index,0:6]\n",
    "                    if(mydata[data_index,6] == 10):\n",
    "                        print(i)\n",
    "                        print(int(mydata[data_index,6]))\n",
    "                    class_count[int(mydata[data_index,6])-1] += 1\n",
    "                    if mydata[data_index,6]==class_to_train:\n",
    "                        label[p_index,ri,ci,0]=1\n",
    "                        \n",
    "# Print out shape and class count\n",
    "print(\"patch shape:\", patch.shape)\n",
    "print(\"label shape:\", label.shape )\n",
    "print('Class count:')\n",
    "for l in range(len(class_count)):\n",
    "    print(\"class\",l+1,\" count\",class_count[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate train set and test set\n",
    "fraction = 0.80\n",
    "\n",
    "# 80% for trainning, 20 % for testing\n",
    "train_num = int(total_sample_num * fraction)\n",
    "test_num = total_sample_num - train_num\n",
    "\n",
    "sample_index = random.sample(range(0,total_sample_num),total_sample_num)\n",
    "train_index = sample_index[:train_num]\n",
    "test_index = sample_index[train_num:]\n",
    "\n",
    "train_x=np.zeros((train_num,size_pat,size_pat,6),float)\n",
    "train_y=np.zeros((train_num,size_pat,size_pat,1),int)\n",
    "for i in range(train_num):\n",
    "    train_x[i] = patch[train_index[i]]\n",
    "    train_y[i] = label[train_index[i]]\n",
    "print(\"Train set shape:\",train_x.shape,\"and\",train_y.shape)\n",
    "\n",
    "test_x=np.zeros((test_num,size_pat,size_pat,6),float)\n",
    "test_y=np.zeros((test_num,size_pat,size_pat,1),int)\n",
    "for i in range(test_num):\n",
    "    test_x[i] = patch[test_index[i]]\n",
    "    test_y[i] = label[test_index[i]]\n",
    "print(\"Test set shape:\",test_x.shape,\"and\",test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "# parameters:\n",
    "num_channel = 64 # if increase this, network reaches higher training accuracy faster and may overfitting\n",
    "size_kernel = (3,3)\n",
    "\n",
    "# The input tensor\n",
    "inputs = Input(shape=(size_pat,size_pat,6))\n",
    "print(\"input shape: \",np.shape(inputs))\n",
    "\n",
    "#layer1 64x64x6 -> 64x64x num_channel\n",
    "layer1 = Conv2D(num_channel, (3, 3),strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(inputs)\n",
    "\n",
    "\n",
    "#layer2 64x64x num_channel -> 32x32x num_channel\n",
    "layer2 = BatchNormalization(axis=-1, momentum=0.01)(layer1)\n",
    "layer2_c = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer2)\n",
    "\n",
    "layer2 = BatchNormalization(axis=-1, momentum=0.01)(layer2_c)\n",
    "layer2 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer2)\n",
    "layer2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(layer2)\n",
    "#9\n",
    "\n",
    "#layer3 32x32x num_channel -> 16x16x num_channel\n",
    "layer3 = BatchNormalization(axis=-1, momentum=0.01)(layer2)\n",
    "layer3 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer3)\n",
    "\n",
    "layer3 = BatchNormalization(axis=-1, momentum=0.01)(layer3)\n",
    "layer3_c = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer3)\n",
    "\n",
    "layer3 = BatchNormalization(axis=-1, momentum=0.01)(layer3_c)\n",
    "layer3 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer3)\n",
    "\n",
    "layer3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(layer3)\n",
    "#19\n",
    "\n",
    "#layer4 16x16x num_channel -> 8x8x num_channel\n",
    "# layer4 = BatchNormalization(axis=-1, momentum=0.01)(layer3)\n",
    "# layer4 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer4)\n",
    "\n",
    "# layer4 = BatchNormalization(axis=-1, momentum=0.01)(layer4)\n",
    "# layer4_c = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer4)\n",
    "\n",
    "# layer4 = BatchNormalization(axis=-1, momentum=0.01)(layer4_c)\n",
    "# layer4 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer4)\n",
    "\n",
    "# layer4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(layer4)\n",
    "\n",
    "\n",
    "#layer4_1 8x8x num_channel -> 4x4x num_channel\n",
    "# layer4_1 = BatchNormalization(axis=-1, momentum=0.01)(layer4)\n",
    "# layer4_1 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='elu')(layer4_1)\n",
    "\n",
    "# layer4_1 = BatchNormalization(axis=-1, momentum=0.01)(layer4_1)\n",
    "# layer4_1_c = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='elu')(layer4_1)\n",
    "\n",
    "# layer4_1 = BatchNormalization(axis=-1, momentum=0.01)(layer4_1_c)\n",
    "# layer4_1 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='elu')(layer4_1)\n",
    "\n",
    "# layer4_1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(layer4_1)\n",
    "\n",
    "\n",
    "#layer5_0 4x4x num_channel -> 8x8x num_channel\n",
    "# layer5_0 = BatchNormalization(axis=-1, momentum=0.01)(layer4_1) #layer4_1 if 64 -> 4\n",
    "# layer5_0 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='elu')(layer5_0)\n",
    "\n",
    "# layer5_0 = BatchNormalization(axis=-1, momentum=0.01)(layer5_0)\n",
    "# layer5_0 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='elu')(layer5_0)\n",
    "\n",
    "# layer5_0 = BatchNormalization(axis=-1, momentum=0.01)(layer5_0)\n",
    "# layer5_0 = Conv2DTranspose(num_channel, size_kernel,strides=(2,2),padding='same',data_format='channels_last',activation='elu')(layer5_0)\n",
    "\n",
    "\n",
    "\n",
    "#layer5 concat and 8x8x num_channel -> 16x16x num_channel\n",
    "#layer5 = concatenate([layer4_1_c,layer5_0],axis=-1) #comment this if 64 -> 8\n",
    "\n",
    "# layer5 = BatchNormalization(axis=-1, momentum=0.01)(layer4) #layer 4 if 64 -> 8\n",
    "# layer5 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer5)\n",
    "\n",
    "# layer5 = BatchNormalization(axis=-1, momentum=0.01)(layer5)\n",
    "# layer5 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer5)\n",
    "\n",
    "# layer5 = BatchNormalization(axis=-1, momentum=0.01)(layer5)\n",
    "# layer5 = Conv2DTranspose(num_channel, size_kernel,strides=(2,2),padding='same',data_format='channels_last',activation='relu')(layer5)\n",
    "\n",
    "\n",
    "#layer6 concat and 16x16x num_channel -> 32x32x num_channel\n",
    "#layer6 = concatenate([layer4_c,layer5],axis=-1)\n",
    "\n",
    "layer6 = BatchNormalization(axis=-1, momentum=0.01)(layer3)\n",
    "layer6 = Conv2D(int(num_channel*1.5), size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer6)\n",
    "\n",
    "layer6 = BatchNormalization(axis=-1, momentum=0.01)(layer6)\n",
    "layer6 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer6)\n",
    "\n",
    "layer6 = BatchNormalization(axis=-1, momentum=0.01)(layer6)\n",
    "layer6 = Conv2DTranspose(num_channel, size_kernel,strides=(2,2),padding='same',data_format='channels_last',activation='relu')(layer6)\n",
    "#28\n",
    "\n",
    "#layer7 concat and 32x32x num_channel -> 64x64x num_channel\n",
    "layer7 = concatenate([layer3_c,layer6],axis=-1)\n",
    "\n",
    "layer7 = BatchNormalization(axis=-1, momentum=0.01)(layer2) #\n",
    "layer7 = Conv2D(int(num_channel*1.5), size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer7)\n",
    "\n",
    "layer7 = BatchNormalization(axis=-1, momentum=0.01)(layer7)\n",
    "layer7 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer7)\n",
    "\n",
    "layer7 = BatchNormalization(axis=-1, momentum=0.01)(layer7)\n",
    "layer7 = Conv2DTranspose(num_channel, size_kernel,strides=(2,2),padding='same',data_format='channels_last',activation='relu')(layer7)\n",
    "#38\n",
    "\n",
    "#output layer8 concat and convout\n",
    "layer8 = concatenate([layer2_c,layer7],axis=-1)\n",
    "\n",
    "layer8 = BatchNormalization(axis=-1, momentum=0.01)(layer8)\n",
    "layer8 = Conv2D(int(num_channel*1.5), size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer8)\n",
    "\n",
    "layer8 = BatchNormalization(axis=-1, momentum=0.01)(layer8)\n",
    "layer8 = Conv2D(num_channel, size_kernel,strides=(1, 1),padding='same',data_format='channels_last',activation='relu')(layer8)\n",
    "\n",
    "layer8 = Conv2D(1, (1, 1),strides=(1,1),padding='same',data_format='channels_last',activation='sigmoid')(layer8)\n",
    "#46\n",
    "model = Model(inputs = inputs, outputs = layer8)\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start training\n",
    "print(\"Start running at: \", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "start = time.clock()\n",
    "model.fit(train_x, train_y,batch_size=32, validation_split=0.3, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print out trainning time and acuracy on test set\n",
    "prediction=model.predict(test_x)\n",
    "elapsed = (time.clock() - start)\n",
    "print(\"Time used(s):\",elapsed)\n",
    "eva = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"Accuracy on test set: \",eva[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function for producing image\n",
    "def produce_img(name,data):\n",
    "    image_data=[0 for i in range(size_pat * size_pat)]\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            image_data[i*size_pat+j] = data[i][j][0] * 256\n",
    "    img = Image.new('L', (size_pat, size_pat))\n",
    "    img.putdata(image_data)\n",
    "    img.save(name)\n",
    "    \n",
    "\n",
    "\n",
    "# Function for printing out comparison between prediction and label\n",
    "def metrics(prediction,label):\n",
    "    all_count = 0\n",
    "    miss_count = 0\n",
    "    right_count = 0\n",
    "    not_good_count = 0\n",
    "    for i in range(len(prediction)):\n",
    "        for j in range(len(prediction[0])):\n",
    "            if label[i][j] == 1:\n",
    "                all_count += 1\n",
    "                if prediction[i][j] >= 0.9:\n",
    "                    right_count += 1\n",
    "                elif prediction[i][j] >= 0.4:\n",
    "                    not_good_count += 1\n",
    "                else:\n",
    "                    miss_count +=1\n",
    "    print('Number of 1s:{0:^7}, right count:{1:^7}, not good count:{2:^7}, miss count:{3:^7}'.\n",
    "          format(all_count,right_count,not_good_count,miss_count))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# Produce 50 images of label and prediction\n",
    "for i in range(50):\n",
    "    sl = 'label_'+str(i)+'.jpg'\n",
    "    sp = 'prediction_'+str(i)+'.jpg'\n",
    "    produce_img(sl,test_y[i])\n",
    "    produce_img(sp,prediction[i])\n",
    "    \n",
    "    \n",
    "# Print out comparison\n",
    "for i in range(len(test_x)):\n",
    "    infor(prediction[i],test_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Examine accuracy on part of train set\n",
    "# train_test_x = train_x[50:100]\n",
    "# train_test_y=train_y[50:100]\n",
    "# eva = model.evaluate(train_test_x, train_test_y, verbose=0)\n",
    "# print(\"Accuracy on part of train set: \",eva[1])\n",
    "# prediction=model.predict(train_test_x)\n",
    "# for i in range(len(train_test_x)):\n",
    "#     sl = 'testlabel_'+str(i)+'.jpg'\n",
    "#     sp = 'test_prediction_'+str(i)+'.jpg'\n",
    "#     produce_img(sl,train_test_y[i])\n",
    "#     produce_img(sp,prediction[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
